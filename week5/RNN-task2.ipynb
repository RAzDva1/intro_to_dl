{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set tf 1.x for colab\n",
    "%tensorflow_version 1.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating names with recurrent neural networks\n",
    "\n",
    "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
    "\n",
    "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
    "\n",
    "It's dangerous to go alone, take these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.696201Z",
     "start_time": "2018-08-13T20:26:38.104103Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import keras_utils\n",
    "import tqdm_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
    "\n",
    "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.701832Z",
     "start_time": "2018-08-13T20:26:42.697766Z"
    }
   },
   "outputs": [],
   "source": [
    "start_token = \" \"  # so that the network knows that we're generating a first token\n",
    "\n",
    "# this is the token for padding,\n",
    "# we will add fake pad token at the end of names \n",
    "# to make them of equal size for further batching\n",
    "pad_token = \"#\"\n",
    "\n",
    "with open(\"names\") as f:\n",
    "    names = f.read()[:-1].split('\\n')\n",
    "    names = [start_token + name for name in names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.707885Z",
     "start_time": "2018-08-13T20:26:42.703302Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples: 7944\n",
      " Abagael\n",
      " Claresta\n",
      " Glory\n",
      " Liliane\n",
      " Prissie\n",
      " Geeta\n",
      " Giovanne\n",
      " Piggy\n"
     ]
    }
   ],
   "source": [
    "print('number of samples:', len(names))\n",
    "for x in names[::1000]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.857411Z",
     "start_time": "2018-08-13T20:26:42.709371Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length: 16\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_LENGTH = max(map(len, names))\n",
    "print(\"max length:\", MAX_LENGTH)\n",
    "\n",
    "plt.title('Sequence length distribution')\n",
    "plt.hist(list(map(len, names)), bins=25);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text processing\n",
    "\n",
    "First we need to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.864592Z",
     "start_time": "2018-08-13T20:26:42.858725Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_tokens: 56\n"
     ]
    }
   ],
   "source": [
    "tokens = list(set(''.join(names))) # all unique characters go here, padding included!\n",
    "tokens.append('#')\n",
    "\n",
    "tokens = list(tokens)\n",
    "n_tokens = len(tokens)\n",
    "print ('n_tokens:', n_tokens)\n",
    "\n",
    "assert 50 < n_tokens < 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cast everything from symbols into identifiers\n",
    "\n",
    "Tensorflow string manipulation is a bit tricky, so we'll work around it. \n",
    "We'll feed our recurrent neural network with ids of characters from our dictionary.\n",
    "\n",
    "To create such dictionary, let's assign `token_to_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.870330Z",
     "start_time": "2018-08-13T20:26:42.866135Z"
    }
   },
   "outputs": [],
   "source": [
    "token_to_id = {v:k for k, v in enumerate(tokens)} # create a dictionary of {symbol -> its  index in tokens}\n",
    "\n",
    "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.875943Z",
     "start_time": "2018-08-13T20:26:42.871834Z"
    }
   },
   "outputs": [],
   "source": [
    "def to_matrix(names, max_len=None, pad=token_to_id[pad_token], dtype=np.int32):\n",
    "    \"\"\"Casts a list of names into rnn-digestable padded matrix\"\"\"\n",
    "    \n",
    "    max_len = max_len or max(map(len, names))\n",
    "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
    "\n",
    "    for i in range(len(names)):\n",
    "        name_ix = list(map(token_to_id.get, names[i]))\n",
    "        names_ix[i, :len(name_ix)] = name_ix\n",
    "\n",
    "    return names_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.883107Z",
     "start_time": "2018-08-13T20:26:42.877186Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Abagael\n",
      " Glory\n",
      " Prissie\n",
      " Giovanne\n",
      "[[28 47 46  9 44  9 49 45 55]\n",
      " [28 13 45 22 17  8 55 55 55]\n",
      " [28  7 17 15 30 30 15 49 55]\n",
      " [28 13 15 22 39  9 21 21 49]]\n"
     ]
    }
   ],
   "source": [
    "# Example: cast 4 random names to padded matrices (so that we can easily batch them)\n",
    "print('\\n'.join(names[::2000]))\n",
    "print(to_matrix(names[::2000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining a recurrent neural network\n",
    "\n",
    "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
    "<img src=\"./rnn.png\" width=600>\n",
    "\n",
    "Since we're training a language model, there should also be:\n",
    "* An embedding layer that converts character id x_t to a vector.\n",
    "* An output layer that predicts probabilities of next phoneme based on h_t+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.039419Z",
     "start_time": "2018-08-13T20:26:42.884581Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From ..\\keras_utils.py:68: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\projects\\ml\\advanced_ml\\venv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:79: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\projects\\ml\\advanced_ml\\venv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:82: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\projects\\ml\\advanced_ml\\venv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:84: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From ..\\keras_utils.py:75: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From ..\\keras_utils.py:77: The name tf.InteractiveSession is deprecated. Please use tf.compat.v1.InteractiveSession instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# remember to reset your session if you change your graph!\n",
    "s = keras_utils.reset_tf_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.044903Z",
     "start_time": "2018-08-13T20:26:44.041084Z"
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import concatenate, Dense, Embedding\n",
    "\n",
    "rnn_num_units = 64  # size of hidden state\n",
    "embedding_size = 16  # for characters\n",
    "\n",
    "# Let's create layers for our recurrent network\n",
    "# Note: we create layers but we don't \"apply\" them yet (this is a \"functional API\" of Keras)\n",
    "# Note: set the correct activation (fromDense(rnn_num_units, activation='relu') keras.activations) to Dense layers!\n",
    "\n",
    "# an embedding layer that converts character ids into embeddings\n",
    "embed_x = Embedding(n_tokens, embedding_size)\n",
    "\n",
    "# a dense layer that maps input and previous state to new hidden state, [x_t,h_t]->h_t+1\n",
    "get_h_next = Dense(rnn_num_units, activation='relu')\n",
    "\n",
    "# a dense layer that maps current hidden state to probabilities of characters [h_t+1]->P(x_t+1|h_t+1)\n",
    "get_probas = Dense(n_tokens, activation='softmax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will generate names character by character starting with `start_token`:\n",
    "\n",
    "<img src=\"./char-nn.png\" width=600>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.053212Z",
     "start_time": "2018-08-13T20:26:44.048389Z"
    }
   },
   "outputs": [],
   "source": [
    "def rnn_one_step(x_t, h_t):\n",
    "    \"\"\"\n",
    "    Recurrent neural network step that produces \n",
    "    probabilities for next token x_t+1 and next state h_t+1\n",
    "    given current input x_t and previous state h_t.\n",
    "    We'll call this method repeatedly to produce the whole sequence.\n",
    "    \n",
    "    You're supposed to \"apply\" above layers to produce new tensors.\n",
    "    Follow inline instructions to complete the function.\n",
    "    \"\"\"\n",
    "    # convert character id into embedding\n",
    "    x_t_emb = embed_x(tf.reshape(x_t, [-1, 1]))[:, 0]\n",
    "    \n",
    "    # concatenate x_t embedding and previous h_t state\n",
    "    x_and_h = concatenate([x_t_emb, h_t], axis = 1)\n",
    "    \n",
    "    # compute next state given x_and_h\n",
    "    h_next = get_h_next(x_and_h)\n",
    "    \n",
    "    # get probabilities for language model P(x_next|h_next)\n",
    "    output_probas = get_probas(h_next)\n",
    "    \n",
    "    return output_probas, h_next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: loop\n",
    "\n",
    "Once `rnn_one_step` is ready, let's apply it in a loop over name characters to get predictions.\n",
    "\n",
    "Let's assume that all names are at most length-16 for now, so we can simply iterate over them in a for loop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.342948Z",
     "start_time": "2018-08-13T20:26:44.056136Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\projects\\ml\\advanced_ml\\venv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3535: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_sequence = tf.placeholder(tf.int32, (None, MAX_LENGTH))  # batch of token ids\n",
    "batch_size = tf.shape(input_sequence)[0]\n",
    "\n",
    "predicted_probas = []\n",
    "h_prev = tf.zeros([batch_size, rnn_num_units])  # initial hidden state\n",
    "\n",
    "for t in range(MAX_LENGTH):\n",
    "    x_t = input_sequence[:, t]  # column t\n",
    "    probas_next, h_next = rnn_one_step(x_t, h_prev)\n",
    "    \n",
    "    h_prev = h_next\n",
    "    predicted_probas.append(probas_next)\n",
    "    \n",
    "# combine predicted_probas into [batch, time, n_tokens] tensor\n",
    "predicted_probas = tf.transpose(tf.stack(predicted_probas), [1, 0, 2])\n",
    "\n",
    "# next to last token prediction is not needed\n",
    "predicted_probas = predicted_probas[:, :-1, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: loss and gradients\n",
    "\n",
    "Let's gather a matrix of predictions for $P(x_{next}|h)$ and the corresponding correct answers.\n",
    "\n",
    "We will flatten our matrices to shape [None, n_tokens] to make it easier.\n",
    "\n",
    "Our network can then be trained by minimizing crossentropy between predicted probabilities and those answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.354310Z",
     "start_time": "2018-08-13T20:26:44.344648Z"
    }
   },
   "outputs": [],
   "source": [
    "# flatten predictions to [batch*time, n_tokens]\n",
    "predictions_matrix = tf.reshape(predicted_probas, [-1, n_tokens])\n",
    "\n",
    "# flatten answers (next tokens) and one-hot encode them\n",
    "answers_matrix = tf.one_hot(tf.reshape(input_sequence[:, 1:], [-1]), n_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually it's a good idea to ignore gradients of loss for padding token predictions.\n",
    "\n",
    "Because we don't care about further prediction after the pad_token is predicted for the first time, so it doesn't make sense to punish our network after the pad_token is predicted.\n",
    "\n",
    "For simplicity you can ignore this comment, it's up to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:45.076642Z",
     "start_time": "2018-08-13T20:26:44.355594Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\projects\\ml\\advanced_ml\\venv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2745: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From d:\\projects\\ml\\advanced_ml\\venv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2749: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\projects\\ml\\advanced_ml\\venv\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# Define the loss as categorical cross-entropy (e.g. from keras.losses).\n",
    "# Mind that predictions are probabilities and NOT logits!\n",
    "# Remember to apply tf.reduce_mean to get a scalar loss!\n",
    "loss = tf.reduce_mean(keras.losses.categorical_crossentropy(answers_matrix, predictions_matrix))\n",
    "\n",
    "optimize = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:55.322187Z",
     "start_time": "2018-08-13T20:26:45.078296Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from random import sample\n",
    "\n",
    "s.run(tf.global_variables_initializer())\n",
    "\n",
    "batch_size = 32\n",
    "history = []\n",
    "\n",
    "for i in range(1000):\n",
    "    batch = to_matrix(sample(names, batch_size), max_len=MAX_LENGTH)\n",
    "    loss_i, _ = s.run([loss, optimize], {input_sequence: batch})\n",
    "    \n",
    "    history.append(loss_i)\n",
    "    \n",
    "    if (i + 1) % 100 == 0:\n",
    "        clear_output(True)\n",
    "        plt.plot(history, label='loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: sampling\n",
    "Once we've trained our network a bit, let's get to actually generating stuff. All we need is the `rnn_one_step` function you have written above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:55.341196Z",
     "start_time": "2018-08-13T20:26:55.323787Z"
    }
   },
   "outputs": [],
   "source": [
    "x_t = tf.placeholder(tf.int32, (1,))\n",
    "h_t = tf.Variable(np.zeros([1, rnn_num_units], np.float32))  # we will update hidden state in this variable\n",
    "\n",
    "# For sampling we need to define `rnn_one_step` tensors only once in our graph.\n",
    "# We reuse all parameters thanks to functional API usage.\n",
    "# Then we can feed appropriate tensor values using feed_dict in a loop.\n",
    "# Note how different it is from training stage, where we had to unroll the whole sequence for backprop.\n",
    "next_probs, next_h = rnn_one_step(x_t, h_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:55.346422Z",
     "start_time": "2018-08-13T20:26:55.342659Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_sample(seed_phrase=start_token, max_length=MAX_LENGTH):\n",
    "    '''\n",
    "    This function generates text given a `seed_phrase` as a seed.\n",
    "    Remember to include start_token in seed phrase!\n",
    "    Parameter `max_length` is used to set the number of characters in prediction.\n",
    "    '''\n",
    "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
    "    s.run(tf.assign(h_t, h_t.initial_value))\n",
    "    \n",
    "    # feed the seed phrase, if any\n",
    "    for ix in x_sequence[:-1]:\n",
    "         s.run(tf.assign(h_t, next_h), {x_t: [ix]})\n",
    "    \n",
    "    # start generating\n",
    "    for _ in range(max_length-len(seed_phrase)):\n",
    "        x_probs,_ = s.run([next_probs, tf.assign(h_t, next_h)], {x_t: [x_sequence[-1]]})\n",
    "        x_sequence.append(np.random.choice(n_tokens, p=x_probs[0]))\n",
    "        \n",
    "    return ''.join([tokens[ix] for ix in x_sequence if tokens[ix] != pad_token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:58.458115Z",
     "start_time": "2018-08-13T20:26:55.347900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Npallie\n",
      " ShYry\n",
      " Mirkhe\n",
      " Lietia\n",
      " faanla\n",
      " Sysue\n",
      " Ja\n",
      " Cetle\n",
      " Mochie\n",
      " Twey\n"
     ]
    }
   ],
   "source": [
    "# without prefix\n",
    "for _ in range(10):\n",
    "    print(generate_sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:01.986726Z",
     "start_time": "2018-08-13T20:26:58.459810Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trump\n",
      " Trumpaa\n",
      " Trumpedd\n",
      " Trumpi\n",
      " Trumpih\n",
      " Trump\n",
      " Trumpal\n",
      " Trumpet\n",
      " Trumpae\n",
      " Trump\n"
     ]
    }
   ],
   "source": [
    "# with prefix conditioning\n",
    "for _ in range(10):\n",
    "    print(generate_sample(' Trump'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Andiys\n",
      " Andilse\n",
      " Ande\n",
      " Andacelt\n",
      " Anda\n",
      " Andarh\n",
      " And\n",
      " Andari\n",
      " Andor\n",
      " Anda\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    print(generate_sample(' And'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit to Coursera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:40:02.004926Z",
     "start_time": "2018-08-13T20:40:02.000821Z"
    }
   },
   "outputs": [],
   "source": [
    "# token expires every 30 min\n",
    "COURSERA_TOKEN = \"kljzEZ4pXnansNMe\"\n",
    "COURSERA_EMAIL = \"iskander0697@gmail.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:40:18.923357Z",
     "start_time": "2018-08-13T20:40:03.549343Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ff0aa7fee894997b49940e75f2b2bfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=25.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submitted to Coursera platform. See results on assignment page!\n"
     ]
    }
   ],
   "source": [
    "from submit import submit_char_rnn\n",
    "samples = [generate_sample(' Al') for i in tqdm_utils.tqdm_notebook_failsafe(range(25))]\n",
    "submission = (history, samples)\n",
    "submit_char_rnn(submission, COURSERA_EMAIL, COURSERA_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try it out!\n",
    "\n",
    "__Disclaimer:__ This part of assignment is entirely optional. You won't receive bonus points for it. However, it's a fun thing to do. Please share your results on course forums.\n",
    "\n",
    "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
    "\n",
    "* Novels/poems/songs of your favorite author\n",
    "* News titles/clickbait titles\n",
    "* Source code of Linux or Tensorflow\n",
    "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
    "* Melody in notes/chords format\n",
    "* IKEA catalog titles\n",
    "* Pokemon names\n",
    "* Cards from Magic, the Gathering / Hearthstone\n",
    "\n",
    "If you're willing to give it a try, here's what you wanna look at:\n",
    "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
    "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
    "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
    "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
    "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
    "\n",
    "__Good hunting!__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Bonus level: dynamic RNNs\n",
    "\n",
    "Apart from Keras, there's also a friendly TensorFlow API for recurrent neural nets. It's based around the symbolic loop function (aka [tf.scan](https://www.tensorflow.org/api_docs/python/tf/scan)).\n",
    "\n",
    "RNN loop that we implemented for training can be replaced with single TensorFlow instruction: [tf.nn.dynamic_rnn](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn).\n",
    "This interface allows for dynamic sequence length and comes with some pre-implemented architectures.\n",
    "\n",
    "Take a look at [tf.nn.rnn_cell.BasicRNNCell](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicRNNCell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:12.975354Z",
     "start_time": "2018-08-13T20:27:12.737529Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-25-5f3812e903bf>:13: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-25-5f3812e903bf>:17: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "RNN cell only supports floating point inputs, but saw dtype: <dtype: 'int32'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-5f3812e903bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0minput_sequence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mpredicted_probas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdynamic_rnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_sequence\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'LSTM outputs for each step [batch,time,n_tokens]:'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\projects\\ml\\advanced_ml\\venv\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m               \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m               instructions)\n\u001b[1;32m--> 324\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[0;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'deprecated'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\projects\\ml\\advanced_ml\\venv\\lib\\site-packages\\tensorflow_core\\python\\ops\\rnn.py\u001b[0m in \u001b[0;36mdynamic_rnn\u001b[1;34m(cell, inputs, sequence_length, initial_state, dtype, parallel_iterations, swap_memory, time_major, scope)\u001b[0m\n\u001b[0;32m    705\u001b[0m         \u001b[0mswap_memory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mswap_memory\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m         \u001b[0msequence_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 707\u001b[1;33m         dtype=dtype)\n\u001b[0m\u001b[0;32m    708\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    709\u001b[0m     \u001b[1;31m# Outputs of _dynamic_rnn_loop are always shaped [time, batch, depth].\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\projects\\ml\\advanced_ml\\venv\\lib\\site-packages\\tensorflow_core\\python\\ops\\rnn.py\u001b[0m in \u001b[0;36m_dynamic_rnn_loop\u001b[1;34m(cell, inputs, initial_state, parallel_iterations, swap_memory, sequence_length, dtype)\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[0mparallel_iterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[0mmaximum_iterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtime_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 916\u001b[1;33m       swap_memory=swap_memory)\n\u001b[0m\u001b[0;32m    917\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    918\u001b[0m   \u001b[1;31m# Unpack final output if not using output tuples.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\projects\\ml\\advanced_ml\\venv\\lib\\site-packages\\tensorflow_core\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[1;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[0;32m   2751\u001b[0m       \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWHILE_CONTEXT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloop_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2752\u001b[0m     result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants,\n\u001b[1;32m-> 2753\u001b[1;33m                                     return_same_structure)\n\u001b[0m\u001b[0;32m   2754\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmaximum_iterations\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2755\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\projects\\ml\\advanced_ml\\venv\\lib\\site-packages\\tensorflow_core\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36mBuildLoop\u001b[1;34m(self, pred, body, loop_vars, shape_invariants, return_same_structure)\u001b[0m\n\u001b[0;32m   2243\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2244\u001b[0m         original_body_result, exit_vars = self._BuildLoop(\n\u001b[1;32m-> 2245\u001b[1;33m             pred, body, original_loop_vars, loop_vars, shape_invariants)\n\u001b[0m\u001b[0;32m   2246\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2247\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\projects\\ml\\advanced_ml\\venv\\lib\\site-packages\\tensorflow_core\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36m_BuildLoop\u001b[1;34m(self, pred, body, original_loop_vars, loop_vars, shape_invariants)\u001b[0m\n\u001b[0;32m   2168\u001b[0m         expand_composites=True)\n\u001b[0;32m   2169\u001b[0m     \u001b[0mpre_summaries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2170\u001b[1;33m     \u001b[0mbody_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mpacked_vars_for_body\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2171\u001b[0m     \u001b[0mpost_summaries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2172\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_sequence_or_composite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\projects\\ml\\advanced_ml\\venv\\lib\\site-packages\\tensorflow_core\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(i, lv)\u001b[0m\n\u001b[0;32m   2703\u001b[0m         cond = lambda i, lv: (  # pylint: disable=g-long-lambda\n\u001b[0;32m   2704\u001b[0m             math_ops.logical_and(i < maximum_iterations, orig_cond(*lv)))\n\u001b[1;32m-> 2705\u001b[1;33m         \u001b[0mbody\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlv\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morig_body\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2706\u001b[0m       \u001b[0mtry_to_pack\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\projects\\ml\\advanced_ml\\venv\\lib\\site-packages\\tensorflow_core\\python\\ops\\rnn.py\u001b[0m in \u001b[0;36m_time_step\u001b[1;34m(time, output_ta_t, state)\u001b[0m\n\u001b[0;32m    882\u001b[0m           skip_conditionals=True)\n\u001b[0;32m    883\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 884\u001b[1;33m       \u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_cell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    885\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    886\u001b[0m     \u001b[1;31m# Keras cells always wrap state as list, even if it's a single tensor.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\projects\\ml\\advanced_ml\\venv\\lib\\site-packages\\tensorflow_core\\python\\ops\\rnn.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    868\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mis_keras_rnn_cell\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    869\u001b[0m       \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 870\u001b[1;33m     \u001b[0mcall_cell\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    871\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    872\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msequence_length\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\projects\\ml\\advanced_ml\\venv\\lib\\site-packages\\tensorflow_core\\python\\ops\\rnn_cell_impl.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, state, scope, *args, **kwargs)\u001b[0m\n\u001b[0;32m    384\u001b[0m     \u001b[1;31m# method.  See the class docstring for more details.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m     return base_layer.Layer.__call__(\n\u001b[1;32m--> 386\u001b[1;33m         self, inputs, state, scope=scope, *args, **kwargs)\n\u001b[0m\u001b[0;32m    387\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\projects\\ml\\advanced_ml\\venv\\lib\\site-packages\\tensorflow_core\\python\\layers\\base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    546\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m       \u001b[1;31m# Actually call layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 548\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    549\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\projects\\ml\\advanced_ml\\venv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    822\u001b[0m           \u001b[1;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    823\u001b[0m           \u001b[1;31m# overridden).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 824\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    825\u001b[0m           \u001b[0mcast_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    826\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\projects\\ml\\advanced_ml\\venv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2144\u001b[0m         \u001b[1;31m# operations.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2145\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2146\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2147\u001b[0m       \u001b[1;31m# We must set self.built since user defined build functions are not\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2148\u001b[0m       \u001b[1;31m# constrained to set self.built.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\projects\\ml\\advanced_ml\\venv\\lib\\site-packages\\tensorflow_core\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(instance, input_shape)\u001b[0m\n\u001b[0;32m    304\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m       \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_shapes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_tuples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 306\u001b[1;33m     \u001b[0moutput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    307\u001b[0m     \u001b[1;31m# Return shapes from `fn` as TensorShapes.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0moutput_shape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\projects\\ml\\advanced_ml\\venv\\lib\\site-packages\\tensorflow_core\\python\\ops\\rnn_cell_impl.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, inputs_shape)\u001b[0m\n\u001b[0;32m    449\u001b[0m       raise ValueError(\"Expected inputs.shape[-1] to be known, saw shape: %s\" %\n\u001b[0;32m    450\u001b[0m                        str(inputs_shape))\n\u001b[1;32m--> 451\u001b[1;33m     \u001b[0m_check_supported_dtypes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[0minput_depth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\projects\\ml\\advanced_ml\\venv\\lib\\site-packages\\tensorflow_core\\python\\ops\\rnn_cell_impl.py\u001b[0m in \u001b[0;36m_check_supported_dtypes\u001b[1;34m(dtype)\u001b[0m\n\u001b[0;32m   1345\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m     raise ValueError(\"RNN cell only supports floating point inputs, \"\n\u001b[1;32m-> 1347\u001b[1;33m                      \"but saw dtype: %s\" % dtype)\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: RNN cell only supports floating point inputs, but saw dtype: <dtype: 'int32'>"
     ]
    }
   ],
   "source": [
    "class CustomRNN(tf.nn.rnn_cell.BasicRNNCell):\n",
    "    def call(self, input, state):\n",
    "        # from docs:\n",
    "        # Returns:\n",
    "        # Output: A 2-D tensor with shape [batch_size, self.output_size].\n",
    "        # New state: Either a single 2-D tensor, or a tuple of tensors matching the arity and shapes of state.\n",
    "        return rnn_one_step(input[:, 0], state)\n",
    "    \n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return n_tokens\n",
    "    \n",
    "cell = CustomRNN(rnn_num_units)\n",
    "\n",
    "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
    "    \n",
    "predicted_probas, last_state = tf.nn.dynamic_rnn(cell, input_sequence[:, :, None], dtype=tf.float32)\n",
    "\n",
    "print('LSTM outputs for each step [batch,time,n_tokens]:')\n",
    "print(predicted_probas.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we never used MAX_LENGTH in the code above: TF will iterate over however many time-steps you gave it.\n",
    "\n",
    "You can also use any pre-implemented RNN cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:12.981697Z",
     "start_time": "2018-08-13T20:27:12.977590Z"
    }
   },
   "outputs": [],
   "source": [
    "for obj in dir(tf.nn.rnn_cell) + dir(tf.contrib.rnn):\n",
    "    if obj.endswith('Cell'):\n",
    "        print(obj, end=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:13.168207Z",
     "start_time": "2018-08-13T20:27:12.986884Z"
    }
   },
   "outputs": [],
   "source": [
    "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
    "\n",
    "inputs_embedded = embed_x(input_sequence)\n",
    "\n",
    "# standard cell returns hidden state as output!\n",
    "cell = tf.nn.rnn_cell.LSTMCell(rnn_num_units)\n",
    "\n",
    "state_sequence, last_state = tf.nn.dynamic_rnn(cell, inputs_embedded, dtype=tf.float32)\n",
    "\n",
    "s.run(tf.global_variables_initializer())\n",
    "\n",
    "print('LSTM hidden state for each step [batch,time,rnn_num_units]:')\n",
    "print(state_sequence.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
